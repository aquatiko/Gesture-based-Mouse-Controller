{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize imports\n",
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "from pymouse import PyMouse\n",
    "from sklearn.metrics import pairwise\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "from scipy.spatial import distance as dist\n",
    "# global variables\n",
    "bg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "# Function - To find the running average over the background\n",
    "#-------------------------------------------------------------------------------\n",
    "def run_avg(image, aWeight):\n",
    "    global bg\n",
    "    # initialize the background\n",
    "    if bg is None:\n",
    "        bg = image.copy().astype(\"float\")\n",
    "        return\n",
    "\n",
    "    # compute weighted average, accumulate it and update the background\n",
    "    cv2.accumulateWeighted(image, bg, aWeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "# Function - To segment the region of hand in the image\n",
    "#-------------------------------------------------------------------------------\n",
    "def segment(image, threshold=25):\n",
    "    global bg\n",
    "    # find the absolute difference between background and current frame\n",
    "    diff = cv2.absdiff(bg.astype(\"uint8\"), image)\n",
    "\n",
    "    # threshold the diff image so that we get the foreground\n",
    "    thresholded = cv2.threshold(diff,\n",
    "                                threshold,\n",
    "                                255,\n",
    "                                cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # get the contours in the thresholded image\n",
    "    (_, cnts, _) = cv2.findContours(thresholded.copy(),\n",
    "                                    cv2.RETR_EXTERNAL,\n",
    "                                    cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # return None, if no contours detected\n",
    "    if len(cnts) == 0:\n",
    "        return\n",
    "    else:\n",
    "        # based on contour area, get the maximum contour which is the hand\n",
    "        segmented = max(cnts, key=cv2.contourArea)\n",
    "        return (thresholded, segmented)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "# Function - To count the number of fingers in the segmented hand region\n",
    "#-------------------------------------------------------------------------------\n",
    "def count(thresholded, segmented):\n",
    "    # find the convex hull of the segmented hand region\n",
    "    chull = cv2.convexHull(segmented)\n",
    "\n",
    "    # find the most extreme points in the convex hull\n",
    "    extreme_top    = tuple(chull[chull[:, :, 1].argmin()][0])\n",
    "    extreme_bottom = tuple(chull[chull[:, :, 1].argmax()][0])\n",
    "    extreme_left   = tuple(chull[chull[:, :, 0].argmin()][0])\n",
    "    extreme_right  = tuple(chull[chull[:, :, 0].argmax()][0])\n",
    "\n",
    "    # find the center of the palm\n",
    "    cX = (extreme_left[0] + extreme_right[0]) // 2\n",
    "    cY = (extreme_top[1] + extreme_bottom[1]) // 2\n",
    "\n",
    "    # find the maximum euclidean distance between the center of the palm\n",
    "    # and the most extreme points of the convex hull\n",
    "    distance = pairwise.euclidean_distances([(cX, cY)], Y=[extreme_left, extreme_right, extreme_top, extreme_bottom])[0]\n",
    "    maximum_distance = distance[distance.argmax()]\n",
    "\n",
    "    # calculate the radius of the circle with 80% of the max euclidean distance obtained\n",
    "    radius = int(0.7 * maximum_distance)\n",
    "    \n",
    "    # find the circumference of the circle\n",
    "    circumference = (2 * np.pi * radius)\n",
    "\n",
    "    # take out the circular region of interest which has \n",
    "    # the palm and the fingers\n",
    "    circular_roi = np.zeros(thresholded.shape[:2], dtype=\"uint8\")\n",
    "    \n",
    "    # draw the circular ROI\n",
    "    cv2.circle(circular_roi, (cX, cY), radius, 255, 1)\n",
    "    \n",
    "    # take bit-wise AND between thresholded hand using the circular ROI as the mask\n",
    "    # which gives the cuts obtained using mask on the thresholded hand image\n",
    "    circular_roi = cv2.bitwise_and(thresholded, thresholded, mask=circular_roi)\n",
    "\n",
    "    # compute the contours in the circular ROI\n",
    "    (_, cnts, _) = cv2.findContours(circular_roi.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # initalize the finger count\n",
    "    count = 0\n",
    "\n",
    "    # loop through the contours found\n",
    "    for c in cnts:\n",
    "        # compute the bounding box of the contour\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "\n",
    "        # increment the count of fingers only if -\n",
    "        # 1. The contour region is not the wrist (bottom area)\n",
    "        # 2. The number of points along the contour does not exceed\n",
    "        #     25% of the circumference of the circular ROI\n",
    "        if ((cY + (cY * 0.25)) > (y + h)) and ((circumference * 0.25) > c.shape[0]):\n",
    "            count += 1\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_aspect_ratio(eye):\n",
    "    # compute the euclidean distances between the two sets of\n",
    "    # vertical eye landmarks (x, y)-coordinates\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    " \n",
    "    # compute the euclidean distance between the horizontal\n",
    "    # eye landmark (x, y)-coordinates\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    " \n",
    "    # compute the eye aspect ratio\n",
    "    ear = (A + B) / (2.0 * C)\n",
    " \n",
    "    # return the eye aspect ratio\n",
    "    return ear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Threshold for Eye Aspect Ratio\n",
    "earThreshold=0.15\n",
    "    \n",
    "#Threshold for blink duration\n",
    "clickThreshold=3\n",
    "    \n",
    "# initialize accumulated weight\n",
    "accumWeight = 0.5\n",
    "\n",
    "#mouse Speed\n",
    "speed=20\n",
    "    \n",
    "#move threshold\n",
    "moveThreshold=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] please wait! calibrating...\n",
      "[STATUS] calibration successfull...\n",
      "[STATUS] please wait! calibrating...\n",
      "[STATUS] calibration successfull...\n",
      "[STATUS] please wait! calibrating...\n",
      "[STATUS] calibration successfull...\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "# Main function\n",
    "#-------------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    #PyMouse object\n",
    "    m=PyMouse()\n",
    "    \n",
    "    # For wink detection\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\") #use link to get file https://drive.google.com/open?id=1r84y_rYPyGuGiuJhXTjtPQHCpCj6w_Ct \n",
    "    \n",
    "    # grab the indexes of the facial landmarks for the left and\n",
    "    # right eye, respectively\n",
    "    (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "    (rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "    \n",
    "    \n",
    "    # get the reference to the webcam\n",
    "    camera = cv2.VideoCapture(0)\n",
    "\n",
    "    # region of interest (ROI) coordinates\n",
    "    top, right, bottom, left = 10, 350, 225, 590\n",
    "\n",
    "    # initialize num of frames\n",
    "    num_frames = 0\n",
    "\n",
    "    # calibration indicator\n",
    "    calibrated = False\n",
    "\n",
    "    #count for blink frames\n",
    "    bCount=0\n",
    "    \n",
    "    \n",
    "    # keep looping, until interrupted\n",
    "    while(True):\n",
    "        # get the current frame\n",
    "        (grabbed, frame) = camera.read()\n",
    "\n",
    "        # resize the frame\n",
    "        frame = imutils.resize(frame, width=700)\n",
    "\n",
    "        # flip the frame so that it is not the mirror view\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # clone the frame\n",
    "        clone = frame.copy()\n",
    "\n",
    "        # get the height and width of the frame\n",
    "        (height, width) = frame.shape[:2]\n",
    "\n",
    "        # get the ROI\n",
    "        roi = frame[top:bottom, right:left]\n",
    "\n",
    "        # convert the roi to grayscale and blur it\n",
    "        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "\n",
    "        # to get the background, keep looking till a threshold is reached\n",
    "        # so that our weighted average model gets calibrated\n",
    "        if num_frames < 30:\n",
    "            run_avg(gray, accumWeight)\n",
    "            if num_frames == 1:\n",
    "                print (\"[STATUS] please wait! calibrating...\")\n",
    "            elif num_frames == 29:\n",
    "                print (\"[STATUS] calibration successfull...\")       \n",
    "        else:\n",
    "            # segment the hand region\n",
    "            hand = segment(gray)\n",
    "            \n",
    "            # detect faces in each frame\n",
    "            rects = detector(clone, 0)\n",
    "            \n",
    "            # loop over the face detections\n",
    "            for rect in rects:\n",
    "            # determine the facial landmarks for the face region, then\n",
    "            # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "            # array\n",
    "                shape = predictor(clone, rect)\n",
    "                shape = face_utils.shape_to_np(shape)\n",
    " \n",
    "                # extract the left and right eye coordinates, then use the\n",
    "                # coordinates to compute the eye aspect ratio for both eyes\n",
    "                leftEye = shape[lStart:lEnd]\n",
    "                rightEye = shape[rStart:rEnd]\n",
    "                leftEAR = eye_aspect_ratio(leftEye)\n",
    "                rightEAR = eye_aspect_ratio(rightEye)\n",
    "                \n",
    "                # compute the convex hull for the left and right eye, then\n",
    "                # visualize each of the eyes\n",
    "                leftEyeHull = cv2.convexHull(leftEye)\n",
    "                rightEyeHull = cv2.convexHull(rightEye)\n",
    "                cv2.drawContours(clone, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "                cv2.drawContours(clone, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "                \n",
    "                if (leftEAR+rightEAR)/2>=earThreshold:\n",
    "                    bCount=0\n",
    "                else:\n",
    "                    bCount+=1\n",
    "                \n",
    "                \n",
    "                cv2.putText(clone, \"Wink=\"+str(bCount), (70, 75), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "                #cv2.putText(clone, \"BlinkRight=\"+str(bCountR), (70, 105), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "                #cv2.putText(clone, \"E.A.R Right=\"+str(rightEAR), (70, 135), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "                #cv2.putText(clone, \"E.A.R Left=\"+str(leftEAR), (70, 165), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "                    \n",
    "                    \n",
    "                if bCount>clickThreshold:          #action for left blink**** assign function to do\n",
    "                    m.click(m.position()[0],m.position()[1],1)\n",
    "                    bCount=0\n",
    "                \n",
    "                \n",
    " \n",
    "\n",
    "            # check whether hand region is segmented\n",
    "            if hand is not None:\n",
    "                # if yes, unpack the thresholded image and\n",
    "                # segmented region\n",
    "                (thresholded, segmented) = hand\n",
    "\n",
    "                # draw the segmented region and display the frame\n",
    "                cv2.drawContours(clone, [segmented + (right, top)], -1, (0, 0, 255))\n",
    "\n",
    "                # count the number of fingers\n",
    "                fingers = count(thresholded, segmented)\n",
    "                \n",
    "                if fingers==1:  #right\n",
    "                    m.move(m.position()[0]+speed,m.position()[1])\n",
    "                    cv2.putText(clone, \"Going->Right\", (70, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "                \n",
    "                elif fingers==2:   #left\n",
    "                    m.move(m.position()[0]-speed,m.position()[1])\n",
    "                    cv2.putText(clone, \"Going->Left\", (70, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "                \n",
    "                elif fingers==3:   #up\n",
    "                    m.move(m.position()[0],m.position()[1]-speed)\n",
    "                    cv2.putText(clone, \"Going->Up\"+str(fingers), (70, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "                \n",
    "                elif fingers==4:   #down\n",
    "                    m.move(m.position()[0],m.position()[1]+speed)\n",
    "                    cv2.putText(clone, \"Going->Down\"+str(fingers), (70, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "                \n",
    "                \n",
    "                else:\n",
    "                    cv2.putText(clone, \"Going->Nowhere\", (70, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "                \n",
    "               \n",
    "                # show the thresholded image\n",
    "                cv2.imshow(\"Thesholded\", thresholded)\n",
    "\n",
    "        # draw the segmented hand\n",
    "        cv2.rectangle(clone, (left, top), (right, bottom), (0,255,0), 2)\n",
    "\n",
    "        # increment the number of frames\n",
    "        num_frames += 1\n",
    "\n",
    "        # display the frame with segmented hand\n",
    "        cv2.imshow(\"Video Feed\", clone)\n",
    "\n",
    "        # observe the keypress by the user\n",
    "        keypress = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # if the user pressed \"q\", then stop looping\n",
    "        if keypress == ord(\"q\"):\n",
    "            break\n",
    "            \n",
    "        #reset background\n",
    "        if keypress == ord(\"r\"):\n",
    "            num_frames=0\n",
    "\n",
    "# free up memory\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
